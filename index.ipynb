{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings for the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at Narrativa/legal-longformer-base-4096-spanish and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"Narrativa/legal-longformer-base-4096-spanish\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('corpus/corpus.csv')  # Replace with your dataset path\n",
    "texts = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]2024-09-25 21:35:13.344187: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-25 21:35:13.357378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-25 21:35:13.374121: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-25 21:35:13.379053: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-25 21:35:13.392026: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 21:35:14.237068: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "100%|██████████| 5000/5000 [22:17<00:00,  3.74it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(5000, 1, 768)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n",
      "\u001b[1;32m     17\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(embedding)\n",
      "\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame for easy handling\u001b[39;00m\n",
      "\u001b[0;32m---> 20\u001b[0m embeddings_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:856\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n",
      "\u001b[1;32m    848\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n",
      "\u001b[1;32m    849\u001b[0m             arrays,\n",
      "\u001b[1;32m    850\u001b[0m             columns,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    853\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n",
      "\u001b[1;32m    854\u001b[0m         )\n",
      "\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 856\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    865\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n",
      "\u001b[1;32m    866\u001b[0m         {},\n",
      "\u001b[1;32m    867\u001b[0m         index,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    870\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n",
      "\u001b[1;32m    871\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:319\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n",
      "\u001b[1;32m    314\u001b[0m     values \u001b[38;5;241m=\u001b[39m _ensure_2d(values)\n",
      "\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n",
      "\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n",
      "\u001b[0;32m--> 319\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_prep_ndarraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n",
      "\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n",
      "\u001b[1;32m    323\u001b[0m     values \u001b[38;5;241m=\u001b[39m sanitize_array(\n",
      "\u001b[1;32m    324\u001b[0m         values,\n",
      "\u001b[1;32m    325\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    328\u001b[0m         allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[1;32m    329\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:582\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[0;34m(values, copy)\u001b[0m\n",
      "\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    580\u001b[0m     values \u001b[38;5;241m=\u001b[39m convert(values)\n",
      "\u001b[0;32m--> 582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:592\u001b[0m, in \u001b[0;36m_ensure_2d\u001b[0;34m(values)\u001b[0m\n",
      "\u001b[1;32m    590\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=(5000, 1, 768)"
     ]
    }
   ],
   "source": [
    "# Function to get embeddings\n",
    "def get_embedding(text, model, tokenizer, device):\n",
    "    # Tokenize the input text and convert to tensors\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=4096, truncation=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  # Move inputs to the correct device\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use the CLS token representation as the sentence embedding\n",
    "    return outputs.last_hidden_state[:, 0, :].cpu().numpy()  # Move to CPU before converting to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Create embeddings for each document\n",
    "for text in tqdm(texts):\n",
    "    embedding = get_embedding(text, model, tokenizer, device)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Convert to DataFrame for easy handling\n",
    "embeddings_df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Embeddings to file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using list comprehension with numpy's reshape to convert (1, 768) -> (768,)\n",
    "embeddings_2d = [embedding.reshape(-1) for embedding in embeddings]\n",
    "\n",
    "# Convert the 2D embeddings list to a DataFrame\n",
    "embeddings_df = pd.DataFrame(embeddings_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.to_csv('corpus/corpus_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(embeddings[0]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
